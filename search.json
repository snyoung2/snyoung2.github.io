[{"authors":null,"categories":null,"content":"","date":1549657674,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549657674,"objectID":"50e4cb74fada19a24deb2f1e20b2fe0c","permalink":"/talk/2019/phenome/","publishdate":"2019-02-08T15:27:54-05:00","relpermalink":"/talk/2019/phenome/","section":"talk","summary":"","tags":[],"title":"Advancements and Challenges in Technology and Data Management Practices of Field-Based, High-Throughput Phenotyping","type":"talk"},{"authors":["**S.N. Young**","J. Peschel"],"categories":null,"content":"","date":1544220581,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544220581,"objectID":"46493ee064522ae72d52c13c6c4f83f7","permalink":"/publication/thms_mmuav/","publishdate":"2018-12-07T17:09:41-05:00","relpermalink":"/publication/thms_mmuav/","section":"publication","summary":"","tags":[],"title":"Visualization for Telemanipulation Tasks by Small, Unmanned Aerial Systems","type":"publication"},{"authors":null,"categories":null,"content":"","date":1538685490,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538685490,"objectID":"9b36f50c47b0a50661854b5c8cc3fe85","permalink":"/talk/2018/asabewater/","publishdate":"2018-10-04T15:38:10-05:00","relpermalink":"/talk/2018/asabewater/","section":"talk","summary":"","tags":[],"title":"Unmanned Systems for Agricultural Water Measurement and Management","type":"talk"},{"authors":[],"categories":[],"content":"The Young Lab is currently seeking highly motivated graduate students to conduct research developing innovative robotics and sensing technologies for agricultural and environmental monitoring. Students will be part of collaborative, multi-disciplinary projects that seek to improve the sensing and sense-making process in diverse applications, including plant phenotying, environmental monitoring, and precision agriculture. The positions are particularly well-suited for students interested in a mixture of hardware development, data analytics, and field work.\nSuccessful candidates are expected to have experiences and interests in one or more of the following areas: mechatronics, robotics, electronics, computer vision, sensing, and/or machine learning, with strong programming skills in one or more of the following languages: MATLAB, LabVIEW, Python, C/C++, and Java.\nInterested applicants are encouraged to send brief description of your research interests and qualifications and curriculum vitae to Dr. Sierra Young at sierrayoung@ncsu.edu.\n","date":1534902285,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534902285,"objectID":"6dfee08ebff5d8293bce69c4d45c4959","permalink":"/post/2018_student_advertisement/","publishdate":"2018-08-21T20:44:45-05:00","relpermalink":"/post/2018_student_advertisement/","section":"post","summary":"Currently seeking highly motivated MS or PhD students in the areas of agricultural robotics and/or environmental sensing.","tags":["news"],"title":"Currently Recruiting Graduate Students in Biological and Agricultural Engineering at NC State","type":"post"},{"authors":["**S.N. Young**","J. Peschel"],"categories":null,"content":"","date":1534885794,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534885794,"objectID":"689260a0d4ccbd2af95653224ff67744","permalink":"/publication/thms/","publishdate":"2018-08-21T16:09:54-05:00","relpermalink":"/publication/thms/","section":"publication","summary":"","tags":[],"title":"Human-Machine Interaction for Telemanipulation by Small Unmanned Systems","type":"publication"},{"authors":["**S.N. Young**","J. Peschel","E. Kayacan"],"categories":null,"content":"","date":1534824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534824000,"objectID":"3e95194336e0591136c80d14c9edd98e","permalink":"/publication/2018_prag/","publishdate":"2018-08-21T00:00:00-04:00","relpermalink":"/publication/2018_prag/","section":"publication","summary":"","tags":[],"title":"“Design and Field Evaluation of a Ground Robot for High-Throughput Phenotyping of Energy Sorghum","type":"publication"},{"authors":["E. Kayacan","**S.N. Young**","J. Peschel","G. Chowdhary"],"categories":null,"content":"Full citation:\nKayacan, E., Young, S.N., Peschel, J., and Chowdhary, G. (2018) “Robot-Assisted Measurement for Hydrologic Understanding in Data Sparse Regions.” J. Field Robotics, 1-13. doi.org/10.1002/rob.21794\n","date":1534824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534824000,"objectID":"4622ae5cd64d9573a891656ccb2b0052","permalink":"/publication/2018_jofr/","publishdate":"2018-08-21T00:00:00-04:00","relpermalink":"/publication/2018_jofr/","section":"publication","summary":"Full citation:\nKayacan, E., Young, S.N., Peschel, J., and Chowdhary, G. (2018) “Robot-Assisted Measurement for Hydrologic Understanding in Data Sparse Regions.” J. Field Robotics, 1-13. doi.org/10.1002/rob.21794","tags":[],"title":"“High Precision Control of Tracked Field Robots in the Presence of Unknown Traction Coefficients","type":"publication"},{"authors":null,"categories":null,"content":"","date":1532982944,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532982944,"objectID":"2ddf7f6acac65230cf67696a21c9a5bf","permalink":"/talk/2018/asabe/","publishdate":"2018-07-30T15:35:44-05:00","relpermalink":"/talk/2018/asabe/","section":"talk","summary":"","tags":[],"title":"Telemanipulation by Unmanned Aerial Vehicles for Agricultural Data Applications","type":"talk"},{"authors":null,"categories":null,"content":"\u0026hellip;\n","date":1530158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530158400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2018-06-28T00:00:00-04:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"},{"authors":null,"categories":null,"content":"","date":1528144074,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528144074,"objectID":"ce3bba46d56f1c7fbd51663a29922c46","permalink":"/talk/2018/ewri/","publishdate":"2018-06-04T15:27:54-05:00","relpermalink":"/talk/2018/ewri/","section":"talk","summary":"","tags":[],"title":"In Situ Measurement of Soil-Water Parameters using a Micro UAV","type":"talk"},{"authors":["**S.N. Young**","J.M. Peschel","G. Penny","S. Thompson","V. Srinivasan"],"categories":null,"content":"Full citation:\nYoung, S. N., Peschel, J.M., Penny, G., Thompson, S., and Srinivasan, V. (2017) “Robot-Assisted Measurement for Hydrologic Understanding in Data Sparse Regions.” Water, 9(7). doi: 10.3390/w9070494\n","date":1498881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498881600,"objectID":"61f03697190c7afd106f0744ced10422","permalink":"/publication/2017_water/","publishdate":"2017-07-01T00:00:00-04:00","relpermalink":"/publication/2017_water/","section":"publication","summary":"This article describes the field application of small, low-cost robots for remote surface data collection and an automated workflow to support water balance computations and hydrologic understanding where water availability data is sparse. Current elevation measurement approaches, such as manual surveying and LiDAR, are costly and infrequent, leading to potential inefficiencies for quantifying the dynamic hydrologic storage capacity of the land surface over large areas. Experiments to evaluate a team of two different robots, including an unmanned aerial vehicle (UAV) and an unmanned surface vehicle (USV), to collect hydrologic surface data utilizing sonar and visual sensors were conducted at three different field sites within the Arkavathy Basin river network located near Bangalore in Karnataka, South India. Visual sensors were used on the UAV to capture high resolution imagery for topographic characterization, and sonar sensors were deployed on the USV to capture bathymetric readings; the data streams were fused in an automated workflow to determine the storage capacity of agricultural reservoirs (also known as ``tanks'') at the three field sites. This study suggests: (i) this robot-assisted methodology is low-cost and suitable for novice users, and (ii) storage capacity data collected at previously unmapped locations revealed strong power-type relationships between surface area, stage, and storage volume, which can be incorporated into modeling of landscape-scale hydrology. This methodology is of importance to water researchers and practitioners because it produces local, high-resolution representations of bathymetry and topography and enables water balance computations at small-watershed scales, which offer insight into the present-day dynamics of a strongly human impacted watershed.","tags":[],"title":"Robot-Assisted Measurement for Hydrologic Understanding in Data Sparse Regions","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"80be3c9fcc86014efab0cec0f14957f6","permalink":"/project/deep-learning/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/deep-learning/","section":"project","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit.","tags":["Deep Learning"],"title":"Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"553a94c5dfd3b8b099d8a12b2d248093","permalink":"/project/example-external-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/example-external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"}]